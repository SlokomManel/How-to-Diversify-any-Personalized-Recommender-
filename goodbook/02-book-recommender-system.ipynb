{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7yIlN7E4dqE"
   },
   "source": [
    "# Books Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eMBXg5P5UKP8",
    "outputId": "3f0a7c62-e5ec-47bc-fc74-cf1fe8ce5f17"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "######\n",
    "from lenskit import batch, topn\n",
    "import lenskit.crossfold as xf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# !pip install lenskit_tf\n",
    "from lenskit import topn, util\n",
    "from lenskit.algorithms import Recommender, item_knn, user_knn as knn, als, tf\n",
    "from lenskit.algorithms import basic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hpCy_uMGUKQN"
   },
   "outputs": [],
   "source": [
    "books = pd.read_csv('goodbook/books.csv')\n",
    "ratings = pd.read_csv('goodbook/ratings.csv')\n",
    "book_tags = pd.read_csv('goodbook/book_tags.csv')\n",
    "tags = pd.read_csv('goodbook/tags.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start with Book tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['art', 'biography', 'business', 'chick lit']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres = [\"Art\", \"Biography\", \"Business\", \"Chick Lit\", \"Children's\", \"Christian\", \"Classics\",\n",
    "          \"Comics\", \"Contemporary\", \"Cookbooks\", \"Crime\", \"Ebooks\", \"Fantasy\", \"Fiction\",\n",
    "          \"Gay and Lesbian\", \"Graphic Novels\", \"Historical Fiction\", \"History\", \"Horror\",\n",
    "          \"Humor and Comedy\", \"Manga\", \"Memoir\", \"Music\", \"Mystery\", \"Nonfiction\", \"Paranormal\",\n",
    "          \"Philosophy\", \"Poetry\", \"Psychology\", \"Religion\", \"Romance\", \"Science\", \"Science Fiction\", \n",
    "          \"Self Help\", \"Suspense\", \"Spirituality\", \"Sports\", \"Thriller\", \"Travel\", \"Young Adult\"]\n",
    "\n",
    "genres = list(map(str.lower, genres))\n",
    "genres[:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_genres = tags.loc[tags.tag_name.str.lower().isin(genres)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60573 books that are tagged with above genres\n"
     ]
    }
   ],
   "source": [
    "available_genres_books = book_tags[book_tags.tag_id.isin(available_genres.tag_id)]\n",
    "print('There are {} books that are tagged with above genres'.format(available_genres_books.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 250 in 35min\n",
    "((950 * 35)/250) #/ 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>tag_id</th>\n",
       "      <th>count</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11305</td>\n",
       "      <td>37174</td>\n",
       "      <td>fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>11743</td>\n",
       "      <td>9954</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>7457</td>\n",
       "      <td>958</td>\n",
       "      <td>classics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>22973</td>\n",
       "      <td>673</td>\n",
       "      <td>paranormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>20939</td>\n",
       "      <td>465</td>\n",
       "      <td>mystery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    goodreads_book_id  tag_id  count       genre\n",
       "1                   1   11305  37174     fantasy\n",
       "5                   1   11743   9954     fiction\n",
       "25                  1    7457    958    classics\n",
       "38                  1   22973    673  paranormal\n",
       "52                  1   20939    465     mystery"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_genres_books['genre'] = available_genres.tag_name.loc[available_genres_books.tag_id].values\n",
    "available_genres_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_genres_books.to_csv (\"RecSys_News/goodbook/available_genres_books.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([200, 200, 199, ...,   2,   2,   2])"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(ratings.groupby('user_id')['rating'].count())[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>314</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>588</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1169</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1185</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981751</th>\n",
       "      <td>10000</td>\n",
       "      <td>48386</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981752</th>\n",
       "      <td>10000</td>\n",
       "      <td>49007</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981753</th>\n",
       "      <td>10000</td>\n",
       "      <td>49383</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981754</th>\n",
       "      <td>10000</td>\n",
       "      <td>50124</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981755</th>\n",
       "      <td>10000</td>\n",
       "      <td>51328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980112 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        book_id  user_id  rating\n",
       "0             1      314       5\n",
       "1             1      439       3\n",
       "2             1      588       5\n",
       "3             1     1169       4\n",
       "4             1     1185       4\n",
       "...         ...      ...     ...\n",
       "981751    10000    48386       5\n",
       "981752    10000    49007       4\n",
       "981753    10000    49383       5\n",
       "981754    10000    50124       5\n",
       "981755    10000    51328       1\n",
       "\n",
       "[980112 rows x 3 columns]"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_ratings = ratings.drop_duplicates(keep='first')\n",
    "dup_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53424\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print (len (dup_ratings.user_id.unique()))\n",
    "print(len (dup_ratings.book_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>tag_id</th>\n",
       "      <th>count</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>314</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11305</td>\n",
       "      <td>37174</td>\n",
       "      <td>fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>314</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11743</td>\n",
       "      <td>9954</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>314</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7457</td>\n",
       "      <td>958</td>\n",
       "      <td>classics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>314</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22973</td>\n",
       "      <td>673</td>\n",
       "      <td>paranormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>314</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>20939</td>\n",
       "      <td>465</td>\n",
       "      <td>mystery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496543</th>\n",
       "      <td>9998</td>\n",
       "      <td>53249</td>\n",
       "      <td>5</td>\n",
       "      <td>9998</td>\n",
       "      <td>14821</td>\n",
       "      <td>21</td>\n",
       "      <td>horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496544</th>\n",
       "      <td>9998</td>\n",
       "      <td>53249</td>\n",
       "      <td>5</td>\n",
       "      <td>9998</td>\n",
       "      <td>8055</td>\n",
       "      <td>18</td>\n",
       "      <td>contemporary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496545</th>\n",
       "      <td>9998</td>\n",
       "      <td>53249</td>\n",
       "      <td>5</td>\n",
       "      <td>9998</td>\n",
       "      <td>23471</td>\n",
       "      <td>17</td>\n",
       "      <td>philosophy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496546</th>\n",
       "      <td>9998</td>\n",
       "      <td>53249</td>\n",
       "      <td>5</td>\n",
       "      <td>9998</td>\n",
       "      <td>10210</td>\n",
       "      <td>7</td>\n",
       "      <td>ebooks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496547</th>\n",
       "      <td>9998</td>\n",
       "      <td>53249</td>\n",
       "      <td>5</td>\n",
       "      <td>9998</td>\n",
       "      <td>20939</td>\n",
       "      <td>6</td>\n",
       "      <td>mystery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496548 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        book_id  user_id  rating  goodreads_book_id  tag_id  count  \\\n",
       "0             1      314       5                  1   11305  37174   \n",
       "1             1      314       5                  1   11743   9954   \n",
       "2             1      314       5                  1    7457    958   \n",
       "3             1      314       5                  1   22973    673   \n",
       "4             1      314       5                  1   20939    465   \n",
       "...         ...      ...     ...                ...     ...    ...   \n",
       "496543     9998    53249       5               9998   14821     21   \n",
       "496544     9998    53249       5               9998    8055     18   \n",
       "496545     9998    53249       5               9998   23471     17   \n",
       "496546     9998    53249       5               9998   10210      7   \n",
       "496547     9998    53249       5               9998   20939      6   \n",
       "\n",
       "               genre  \n",
       "0            fantasy  \n",
       "1            fiction  \n",
       "2           classics  \n",
       "3         paranormal  \n",
       "4            mystery  \n",
       "...              ...  \n",
       "496543        horror  \n",
       "496544  contemporary  \n",
       "496545    philosophy  \n",
       "496546        ebooks  \n",
       "496547       mystery  \n",
       "\n",
       "[496548 rows x 7 columns]"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_genres_books = book_tags[book_tags.tag_id.isin(available_genres.tag_id)]\n",
    "available_genres_books [\"book_id\"] = available_genres_books [\"goodreads_book_id\"]\n",
    "available_genres_books['genre'] = available_genres.tag_name.loc[available_genres_books.tag_id].values\n",
    "\n",
    "# Merge the DataFrames based on the 'book_id' column\n",
    "genres_ratings = dup_ratings.merge(available_genres_books, on='book_id', how='inner')\n",
    "genres_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>314</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>314</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>314</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>classics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>314</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>paranormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>mystery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496543</th>\n",
       "      <td>53249</td>\n",
       "      <td>9998</td>\n",
       "      <td>5</td>\n",
       "      <td>horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496544</th>\n",
       "      <td>53249</td>\n",
       "      <td>9998</td>\n",
       "      <td>5</td>\n",
       "      <td>contemporary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496545</th>\n",
       "      <td>53249</td>\n",
       "      <td>9998</td>\n",
       "      <td>5</td>\n",
       "      <td>philosophy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496546</th>\n",
       "      <td>53249</td>\n",
       "      <td>9998</td>\n",
       "      <td>5</td>\n",
       "      <td>ebooks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496547</th>\n",
       "      <td>53249</td>\n",
       "      <td>9998</td>\n",
       "      <td>5</td>\n",
       "      <td>mystery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496548 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  book_id  rating         genre\n",
       "0           314        1       5       fantasy\n",
       "1           314        1       5       fiction\n",
       "2           314        1       5      classics\n",
       "3           314        1       5    paranormal\n",
       "4           314        1       5       mystery\n",
       "...         ...      ...     ...           ...\n",
       "496543    53249     9998       5        horror\n",
       "496544    53249     9998       5  contemporary\n",
       "496545    53249     9998       5    philosophy\n",
       "496546    53249     9998       5        ebooks\n",
       "496547    53249     9998       5       mystery\n",
       "\n",
       "[496548 rows x 4 columns]"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fil = genres_ratings[['user_id', 'book_id', 'rating', 'genre']]\n",
    "df_fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>484516</th>\n",
       "      <td>2</td>\n",
       "      <td>9762</td>\n",
       "      <td>4</td>\n",
       "      <td>philosophy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484513</th>\n",
       "      <td>2</td>\n",
       "      <td>9762</td>\n",
       "      <td>4</td>\n",
       "      <td>psychology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484514</th>\n",
       "      <td>2</td>\n",
       "      <td>9762</td>\n",
       "      <td>4</td>\n",
       "      <td>spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484517</th>\n",
       "      <td>2</td>\n",
       "      <td>9762</td>\n",
       "      <td>4</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484515</th>\n",
       "      <td>2</td>\n",
       "      <td>9762</td>\n",
       "      <td>4</td>\n",
       "      <td>nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201189</th>\n",
       "      <td>53424</td>\n",
       "      <td>4214</td>\n",
       "      <td>5</td>\n",
       "      <td>classics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201188</th>\n",
       "      <td>53424</td>\n",
       "      <td>4214</td>\n",
       "      <td>5</td>\n",
       "      <td>fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201195</th>\n",
       "      <td>53424</td>\n",
       "      <td>4214</td>\n",
       "      <td>5</td>\n",
       "      <td>ebooks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201196</th>\n",
       "      <td>53424</td>\n",
       "      <td>4214</td>\n",
       "      <td>5</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201194</th>\n",
       "      <td>53424</td>\n",
       "      <td>4214</td>\n",
       "      <td>5</td>\n",
       "      <td>spirituality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496548 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  book_id  rating         genre\n",
       "484516        2     9762       4    philosophy\n",
       "484513        2     9762       4    psychology\n",
       "484514        2     9762       4  spirituality\n",
       "484517        2     9762       4      religion\n",
       "484515        2     9762       4    nonfiction\n",
       "...         ...      ...     ...           ...\n",
       "201189    53424     4214       5      classics\n",
       "201188    53424     4214       5       fantasy\n",
       "201195    53424     4214       5        ebooks\n",
       "201196    53424     4214       5        travel\n",
       "201194    53424     4214       5  spirituality\n",
       "\n",
       "[496548 rows x 4 columns]"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_sorted = df_fil.sort_values(by='user_id')\n",
    "ratings_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>9762</td>\n",
       "      <td>philosophy, psychology, spirituality, religion...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>9014</td>\n",
       "      <td>thriller, fantasy, fiction, horror, ebooks, sc...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3273</td>\n",
       "      <td>ebooks, travel, contemporary, fiction, history...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1519</td>\n",
       "      <td>fantasy, philosophy, history, poetry, fiction,...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>3711</td>\n",
       "      <td>religion, classics, contemporary, fiction</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79526</th>\n",
       "      <td>53420</td>\n",
       "      <td>4625</td>\n",
       "      <td>ebooks, classics, fiction</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79527</th>\n",
       "      <td>53420</td>\n",
       "      <td>6538</td>\n",
       "      <td>nonfiction, history, suspense, ebooks, science...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79528</th>\n",
       "      <td>53422</td>\n",
       "      <td>7667</td>\n",
       "      <td>suspense, mystery, thriller, fiction, crime, s...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79529</th>\n",
       "      <td>53423</td>\n",
       "      <td>4984</td>\n",
       "      <td>classics, fiction, biography, ebooks, science,...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79530</th>\n",
       "      <td>53424</td>\n",
       "      <td>4214</td>\n",
       "      <td>religion, fiction, philosophy, contemporary, c...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79531 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  book_id                                              genre  \\\n",
       "0            2     9762  philosophy, psychology, spirituality, religion...   \n",
       "1            3     9014  thriller, fantasy, fiction, horror, ebooks, sc...   \n",
       "2            4     3273  ebooks, travel, contemporary, fiction, history...   \n",
       "3            7     1519  fantasy, philosophy, history, poetry, fiction,...   \n",
       "4            7     3711          religion, classics, contemporary, fiction   \n",
       "...        ...      ...                                                ...   \n",
       "79526    53420     4625                          ebooks, classics, fiction   \n",
       "79527    53420     6538  nonfiction, history, suspense, ebooks, science...   \n",
       "79528    53422     7667  suspense, mystery, thriller, fiction, crime, s...   \n",
       "79529    53423     4984  classics, fiction, biography, ebooks, science,...   \n",
       "79530    53424     4214  religion, fiction, philosophy, contemporary, c...   \n",
       "\n",
       "       rating  \n",
       "0         4.0  \n",
       "1         1.0  \n",
       "2         2.0  \n",
       "3         5.0  \n",
       "4         5.0  \n",
       "...       ...  \n",
       "79526     3.0  \n",
       "79527     4.0  \n",
       "79528     4.0  \n",
       "79529     5.0  \n",
       "79530     5.0  \n",
       "\n",
       "[79531 rows x 4 columns]"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = ratings_sorted.groupby(['user_id', 'book_id']).agg({'genre': ', '.join, 'rating': 'mean'}).reset_index()\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter book_ids with less than 10 ratings\n",
    "book_counts = grouped_df['book_id'].value_counts()\n",
    "popular_books = book_counts[book_counts >= 3].index\n",
    "df_filtered_books = grouped_df[grouped_df['book_id'].isin(popular_books)]\n",
    "\n",
    "# Step 2: Filter users with less than 20 interactions\n",
    "user_counts = df_filtered_books['user_id'].value_counts()\n",
    "active_users = user_counts[user_counts >= 10].index\n",
    "df_filtered = df_filtered_books[df_filtered_books['user_id'].isin(active_users)]\n",
    "\n",
    "# Step 3: Reset the indices of the filtered DataFrame\n",
    "df_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Now, df_filtered contains the data where book_ids have at least 10 ratings, users have at least 20 interactions, and the indices are reset.\n",
    "\n",
    "# Step 4: Create mapping dictionaries for book_id and user_id to integer indices\n",
    "book_id_to_index = {book_id: index+1 for index, book_id in enumerate(df_filtered['book_id'].unique())}\n",
    "user_id_to_index = {user_id: index+1 for index, user_id in enumerate(df_filtered['user_id'].unique())}\n",
    "\n",
    "# Step 5: Map book_id and user_id to integer indices in the DataFrame\n",
    "df_filtered['book_index'] = df_filtered['book_id'].map(book_id_to_index)\n",
    "df_filtered['user_index'] = df_filtered['user_id'].map(user_id_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_index</th>\n",
       "      <th>book_index</th>\n",
       "      <th>rating</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>classics, fiction, fantasy, contemporary, myst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fiction, classics, fantasy, ebooks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>classics, science, fiction, fantasy, philosoph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>science, ebooks, religion, philosophy, classic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ebooks, fiction, classics, contemporary, roman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ebooks, romance, biography, fiction, contempor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>religion, ebooks, spirituality, romance, philo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>romance, contemporary, fiction, classics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>fiction, contemporary, classics, crime, scienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>religion, fantasy, history, art, romance, eboo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>history, romance, ebooks, fiction, classics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ebooks, fiction, romance, contemporary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ebooks, contemporary, romance, memoir, classic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>romance, poetry, classics, philosophy, religio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>fiction, contemporary, history, ebooks, biogra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>nonfiction, music, fiction, memoir, contempora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>mystery, contemporary, ebooks, fantasy, scienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>4.0</td>\n",
       "      <td>business, classics, philosophy, nonfiction, sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>5.0</td>\n",
       "      <td>philosophy, business, art, spirituality, nonfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>paranormal, fiction, fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ebooks, classics, music, fiction, history, con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>horror, fiction, mystery, fantasy, romance, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>4.0</td>\n",
       "      <td>classics, science, nonfiction, philosophy, bio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>fiction, classics, paranormal, mystery, romanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>3.0</td>\n",
       "      <td>classics, paranormal, mystery, contemporary, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>4.0</td>\n",
       "      <td>contemporary, mystery, paranormal, classics, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>fantasy, contemporary, mystery, paranormal, cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>contemporary, ebooks, history, nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>fiction, fantasy, classics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>4.0</td>\n",
       "      <td>fantasy, art, fiction, nonfiction, science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nonfiction, ebooks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>3.0</td>\n",
       "      <td>fiction, fantasy, classics, science, ebooks, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>religion, ebooks, philosophy, science, classic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>history, suspense, contemporary, fantasy, crim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>4.0</td>\n",
       "      <td>science, classics, fantasy, fiction, travel, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>contemporary, memoir, fiction, classics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>4.0</td>\n",
       "      <td>fiction, classics, romance, contemporary, ebooks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>romance, science, fantasy, ebooks, contemporar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>suspense, ebooks, thriller, classics, crime, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>history, philosophy, religion, psychology, cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>3.0</td>\n",
       "      <td>history, nonfiction, biography, classics, eboo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>3.0</td>\n",
       "      <td>contemporary, fiction, mystery, fantasy, roman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>2.0</td>\n",
       "      <td>memoir, religion, horror, contemporary, biogra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>fiction, romance, contemporary, ebooks, classics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>suspense, fiction, crime, classics, thriller, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nonfiction, science, history, philosophy, clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ebooks, philosophy, history, science, nonficti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>3.0</td>\n",
       "      <td>classics, fiction, travel, romance, history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>2.0</td>\n",
       "      <td>nonfiction, memoir, contemporary, biography, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>mystery, suspense, contemporary, fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_index  book_index  rating  \\\n",
       "0            1           1     5.0   \n",
       "1            1           2     1.0   \n",
       "2            1           3     2.0   \n",
       "3            1           4     5.0   \n",
       "4            1           5     4.0   \n",
       "5            1           6     4.0   \n",
       "6            1           7     4.0   \n",
       "7            1           8     5.0   \n",
       "8            1           9     3.0   \n",
       "9            1          10     2.0   \n",
       "10           1          11     4.0   \n",
       "11           1          12     5.0   \n",
       "12           2           5     5.0   \n",
       "13           2           7     4.0   \n",
       "14           2          13     5.0   \n",
       "15           2          14     5.0   \n",
       "16           2          15     4.0   \n",
       "17           2          16     4.0   \n",
       "18           2          17     5.0   \n",
       "19           2          18     5.0   \n",
       "20           2          19     5.0   \n",
       "21           2          20     5.0   \n",
       "22           2          21     4.0   \n",
       "23           3          22     5.0   \n",
       "24           3          23     3.0   \n",
       "25           3          24     4.0   \n",
       "26           3           1     5.0   \n",
       "27           3          25     3.0   \n",
       "28           3          26     4.0   \n",
       "29           3          27     4.0   \n",
       "30           3          28     3.0   \n",
       "31           3          29     3.0   \n",
       "32           3           3     4.0   \n",
       "33           3          30     3.0   \n",
       "34           3          31     4.0   \n",
       "35           3          32     3.0   \n",
       "36           3          33     4.0   \n",
       "37           3          34     3.0   \n",
       "38           3          35     3.0   \n",
       "39           3          36     2.0   \n",
       "40           4          37     3.0   \n",
       "41           4          38     3.0   \n",
       "42           4          39     2.0   \n",
       "43           4          40     3.0   \n",
       "44           4          35     3.0   \n",
       "45           4          41     3.0   \n",
       "46           4          42     2.0   \n",
       "47           4          43     3.0   \n",
       "48           4          44     2.0   \n",
       "49           4          45     2.0   \n",
       "\n",
       "                                                genre  \n",
       "0   classics, fiction, fantasy, contemporary, myst...  \n",
       "1                  fiction, classics, fantasy, ebooks  \n",
       "2   classics, science, fiction, fantasy, philosoph...  \n",
       "3   science, ebooks, religion, philosophy, classic...  \n",
       "4   ebooks, fiction, classics, contemporary, roman...  \n",
       "5   ebooks, romance, biography, fiction, contempor...  \n",
       "6   religion, ebooks, spirituality, romance, philo...  \n",
       "7            romance, contemporary, fiction, classics  \n",
       "8   fiction, contemporary, classics, crime, scienc...  \n",
       "9   religion, fantasy, history, art, romance, eboo...  \n",
       "10        history, romance, ebooks, fiction, classics  \n",
       "11             ebooks, fiction, romance, contemporary  \n",
       "12  ebooks, contemporary, romance, memoir, classic...  \n",
       "13  romance, poetry, classics, philosophy, religio...  \n",
       "14  fiction, contemporary, history, ebooks, biogra...  \n",
       "15  nonfiction, music, fiction, memoir, contempora...  \n",
       "16  mystery, contemporary, ebooks, fantasy, scienc...  \n",
       "17  business, classics, philosophy, nonfiction, sc...  \n",
       "18  philosophy, business, art, spirituality, nonfi...  \n",
       "19                       paranormal, fiction, fantasy  \n",
       "20  ebooks, classics, music, fiction, history, con...  \n",
       "21  horror, fiction, mystery, fantasy, romance, th...  \n",
       "22  classics, science, nonfiction, philosophy, bio...  \n",
       "23  fiction, classics, paranormal, mystery, romanc...  \n",
       "24  classics, paranormal, mystery, contemporary, f...  \n",
       "25  contemporary, mystery, paranormal, classics, f...  \n",
       "26  fantasy, contemporary, mystery, paranormal, cl...  \n",
       "27          contemporary, ebooks, history, nonfiction  \n",
       "28                         fiction, fantasy, classics  \n",
       "29         fantasy, art, fiction, nonfiction, science  \n",
       "30                                 nonfiction, ebooks  \n",
       "31  fiction, fantasy, classics, science, ebooks, r...  \n",
       "32  religion, ebooks, philosophy, science, classic...  \n",
       "33  history, suspense, contemporary, fantasy, crim...  \n",
       "34  science, classics, fantasy, fiction, travel, e...  \n",
       "35            contemporary, memoir, fiction, classics  \n",
       "36   fiction, classics, romance, contemporary, ebooks  \n",
       "37  romance, science, fantasy, ebooks, contemporar...  \n",
       "38  suspense, ebooks, thriller, classics, crime, f...  \n",
       "39  history, philosophy, religion, psychology, cla...  \n",
       "40  history, nonfiction, biography, classics, eboo...  \n",
       "41  contemporary, fiction, mystery, fantasy, roman...  \n",
       "42  memoir, religion, horror, contemporary, biogra...  \n",
       "43   fiction, romance, contemporary, ebooks, classics  \n",
       "44  suspense, fiction, crime, classics, thriller, ...  \n",
       "45  nonfiction, science, history, philosophy, clas...  \n",
       "46  ebooks, philosophy, history, science, nonficti...  \n",
       "47        classics, fiction, travel, romance, history  \n",
       "48  nonfiction, memoir, contemporary, biography, f...  \n",
       "49           mystery, suspense, contemporary, fiction  "
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = df_filtered[['user_index', 'book_index', 'rating', 'genre']]\n",
    "grouped_df.head (50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique user_ids: 943\n",
      "Number of unique book_ids: 761\n",
      "Sparsity of the data: 0.9816\n"
     ]
    }
   ],
   "source": [
    "# grouped_df= df_filtered.copy()\n",
    "# Number of unique user_ids and book_ids\n",
    "num_unique_users = grouped_df['user_index'].nunique()\n",
    "num_unique_books = grouped_df['book_index'].nunique()\n",
    "\n",
    "# Total possible interactions (assuming all combinations exist)\n",
    "total_possible_interactions = num_unique_users * num_unique_books\n",
    "\n",
    "# Actual number of interactions (non-zero ratings)\n",
    "num_interactions = grouped_df.shape[0]\n",
    "\n",
    "# Sparsity calculation\n",
    "sparsity = 1.0 - (num_interactions / total_possible_interactions)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of unique user_ids: {num_unique_users}\")\n",
    "print(f\"Number of unique book_ids: {num_unique_books}\")\n",
    "print(f\"Sparsity of the data: {sparsity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tp in enumerate(xf.partition_users(grouped_df, 1, xf.SampleN(5))):\n",
    "  tp.train.to_csv('train-book%d.csv' % (i,), index= False)\n",
    "  tp.test.to_csv('val-book%d.csv' % (i,), index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df.to_csv (\"goodbook/ratings_filtered_goodbook.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"goodbook/trainVal-book0.csv\")\n",
    "for i, tp in enumerate(xf.partition_users(grouped_df, 1, xf.SampleN(5))):\n",
    "  tp.train.to_csv('train-book%d.csv' % (i,), index= False)\n",
    "  tp.test.to_csv('val-book%d.csv' % (i,), index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df.to_csv(\"goodbook/processed_GB_Data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "######\n",
    "from lenskit import batch, topn\n",
    "import lenskit.crossfold as xf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# !pip install lenskit_tf\n",
    "from lenskit import topn, util\n",
    "from lenskit.algorithms import Recommender, als, tf\n",
    "from lenskit.algorithms import basic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_obfuscation = 0.01\n",
    "preprocess = [\"1Step\", \"2Step\", \"original\"][1]\n",
    "mode = [\"strategic\", \"random\"][0]\n",
    "topk = [5, 10][0] #\n",
    "round = [1, 2, 3][1]\n",
    "# train = pd.read_csv (\"goodbook/trainVal-book0.csv\", sep=\",\", names= [\"user\", \"item\", \"rating\", \"genre\"]) # \n",
    "# train = pd.read_csv (f\"goodbook/Random/Adding_user_item_matrix_{p_obfuscation}_top50Inditems_top100IndiUsers_Categories.csv\", sep=\",\", names= [\"user\", \"item\"])#, \"rating\", \"genre\"]) # \n",
    "train = pd.read_csv (f\"goodbook/Random/obfuscated_user_item_matrix_{p_obfuscation}_{mode}_top50Inditems_top100IndiUsers_Categories.csv\", sep=\",\", names= [\"user\", \"item\"])#, \"rating\", \"genre\"]) # \n",
    "# val = pd.read_csv (\"goodbook/val-book0.csv\", sep=\",\", names= [\"user\", \"item\", \"rating\", \"genre\"])\n",
    "test = pd.read_csv (\"goodbook/test-book0.csv\", sep=\",\", names= [\"user\", \"item\", \"rating\", \"genre\"])\n",
    "topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_id</td>\n",
       "      <td>item_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7890</th>\n",
       "      <td>943</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7891</th>\n",
       "      <td>943</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7892</th>\n",
       "      <td>943</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7893</th>\n",
       "      <td>943</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7894</th>\n",
       "      <td>943</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7895 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user     item\n",
       "0     user_id  item_id\n",
       "1           1        3\n",
       "2           1        4\n",
       "3           1        5\n",
       "4           1        7\n",
       "...       ...      ...\n",
       "7890      943       88\n",
       "7891      943       90\n",
       "7892      943      109\n",
       "7893      943      127\n",
       "7894      943      381\n",
       "\n",
       "[7895 rows x 2 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique user_ids: 944\n",
      "Number of unique book_ids: 705\n",
      "Sparsity of the data: 0.9881\n",
      "lentgh of the data:  7895\n"
     ]
    }
   ],
   "source": [
    "# grouped_df= df_filtered.copy()\n",
    "# Number of unique user_ids and book_ids\n",
    "num_unique_users = train['user'].nunique()\n",
    "num_unique_books = train['item'].nunique()\n",
    "\n",
    "# Total possible interactions (assuming all combinations exist)\n",
    "total_possible_interactions = num_unique_users * num_unique_books\n",
    "\n",
    "# Actual number of interactions (non-zero ratings)\n",
    "num_interactions = train.shape[0]\n",
    "\n",
    "# Sparsity calculation\n",
    "sparsity = 1.0 - (num_interactions / total_possible_interactions)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of unique user_ids: {num_unique_users}\")\n",
    "print(f\"Number of unique book_ids: {num_unique_books}\")\n",
    "print(f\"Sparsity of the data: {sparsity:.4f}\")\n",
    "print(f\"lentgh of the data: \", len (train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "train [\"rating\"] = 1\n",
    "train = train [[\"user\", \"item\", \"rating\"]] #.copy ()\n",
    "# trainVal_small.to_csv (\"goodbook/trainVal_small.csv\", index= False)\\\n",
    "\n",
    "# val_small = train [[\"user\", \"item\", \"rating\"]] #.copy ()\n",
    "# train_small.to_csv (\"goodbook/train_small.csv\", index= False)\n",
    "test [\"rating\"] = 1\n",
    "test = test [[\"user\", \"item\", \"rating\"]] #.copy ()\n",
    "# test_small.to_csv (\"goodbook/test_small.csv\", index= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique user_ids: 943\n",
      "Number of unique book_ids: 721\n",
      "Sparsity of the data: 0.9861\n",
      "Length of the data: 9446\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.7137\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7126\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7109\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7092\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7077\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7063\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7047\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7035\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7019\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7004\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6990\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6978\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6963\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6947\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6936\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6920\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6905\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6890\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6874\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6867\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6847\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6836\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6821\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6806\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6793\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6781\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6767\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6753\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6741\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6723\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6710\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6692\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6677\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6665\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6647\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6635\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6613\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6601\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6582\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6566\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6550\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6536\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6517\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6504\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6484\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6461\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6448\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6429\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6410\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6390\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6370\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6345\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6331\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6312\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6288\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6265\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6240\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6223\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6201\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6177\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6152\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6129\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6103\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6079\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6056\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6031\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6002\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5978\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5952\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5922\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5889\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5876\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5834\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5810\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5777\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5752\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5722\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5687\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5661\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5627\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5603\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5565\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5543\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5501\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5481\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5448\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5405\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5373\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5338\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5299\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5270\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5228\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5199\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5172\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5140\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5103\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5075\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5037\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5002\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4959\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4941\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4922\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4879\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4837\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4812\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4770\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4743\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4712\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4667\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4642\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4621\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4576\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4550\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4526\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4490\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4463\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4435\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4395\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4364\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4348\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4309\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4281\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4257\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4232\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4188\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4189\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4156\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4129\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4072\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4065\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4038\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4017\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3999\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3973\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3928\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3886\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3891\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3855\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3842\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3834\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3795\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3763\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3777\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3767\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3730\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3713\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3693\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3645\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3611\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3618\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3614\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3586\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3565\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3560\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3534\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3529\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3484\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3489\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3464\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3433\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3441\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3416\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3414\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3373\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3386\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3361\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3353\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3346\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3310\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3287\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3290\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3295\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3271\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3240\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3243\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3232\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3220\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3216\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3187\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3169\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3172\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3149\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3134\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3098\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3136\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3107\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3095\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3097\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3097\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3093\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3061\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3059\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3048\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3040\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3024\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3039\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3017\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3012\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2984\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2981\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.7140\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7125\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7112\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7094\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7077\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7063\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7051\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7035\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7020\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7008\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6992\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6977\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6964\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6947\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6933\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6918\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6905\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6897\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6877\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6861\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6849\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6835\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6823\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6806\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6792\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6778\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6765\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6747\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6735\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6721\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6709\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6693\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6675\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6660\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6645\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6632\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6614\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6596\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6581\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6563\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6552\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6533\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6513\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6498\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6480\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6464\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6443\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6426\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6408\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6391\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6367\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6348\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6326\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6306\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6284\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6265\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6240\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6218\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6196\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6171\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6148\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6126\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6103\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6081\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6053\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6028\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5995\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5977\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5948\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5920\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5891\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5865\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5842\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5805\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5776\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5752\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5721\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5694\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5659\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5631\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5596\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5566\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5540\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5494\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5473\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5441\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5408\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5374\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5343\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5313\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5269\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5244\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5209\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5171\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5143\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5113\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5077\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5045\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5012\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4989\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4956\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4895\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4878\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4837\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4816\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4777\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4742\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4711\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4681\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4635\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4603\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4583\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4543\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4529\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4485\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4459\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4424\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4390\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4395\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4341\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4291\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4294\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4247\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4232\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4194\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4176\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4138\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4126\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4092\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4068\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4029\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3993\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4002\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3968\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3944\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3924\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3912\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3867\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3867\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3802\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3809\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3791\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3776\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3737\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3725\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3682\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3691\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3663\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3617\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3621\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3602\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3580\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3569\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3551\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3546\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3522\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3506\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3458\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3446\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3449\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3433\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3412\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3418\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3406\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3359\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3348\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3344\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3324\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3313\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3306\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3280\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3256\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3257\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3258\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3230\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3228\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3222\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3171\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3194\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3180\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3167\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3133\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3147\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3114\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3119\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3086\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3072\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3084\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3077\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3059\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3056\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3033\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3041\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3036\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3028\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3020\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3023\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.2980\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2984\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2978\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.7137\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7120\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7110\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7092\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7080\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7067\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7048\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7035\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7022\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7006\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6992\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6974\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6963\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6947\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6934\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6920\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6909\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6891\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6878\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6863\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6847\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6837\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6820\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6808\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6793\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6778\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6768\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6749\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6736\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6720\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6707\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6692\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6675\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6665\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6647\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6630\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6617\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6600\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6585\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6567\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6550\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6533\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6513\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6501\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6483\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6460\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6440\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6425\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6406\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6390\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6370\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6349\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6331\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6312\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6291\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6271\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6245\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6221\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6196\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6179\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6152\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6129\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6104\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6080\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6054\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6027\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6004\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5977\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5952\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5923\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5896\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5865\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5840\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5814\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5784\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5755\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5723\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5696\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5662\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5627\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5595\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5573\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5541\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5506\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5470\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5438\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5415\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5373\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5345\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5313\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5280\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5254\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5215\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5171\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5145\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5121\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5087\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5031\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5005\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4978\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4944\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4904\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4873\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4838\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4822\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4772\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4747\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4718\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4678\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4652\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4615\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4569\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4559\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4525\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4481\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4457\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4429\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4403\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4373\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4331\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4313\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4296\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4263\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4225\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4190\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4164\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4137\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4127\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4064\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4051\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4025\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4008\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3990\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3953\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3922\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3911\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3892\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3868\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3838\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3813\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3801\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3779\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3749\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3749\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3723\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3693\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3676\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3642\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3627\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3594\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3608\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3591\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3547\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3525\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3533\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3505\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3483\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3482\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3467\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3458\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3428\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3413\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3388\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3372\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3382\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3336\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3318\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3323\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3316\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3284\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3262\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3263\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3242\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3215\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3202\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3226\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3167\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3180\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3164\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3157\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3168\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3124\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3134\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3150\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3109\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3098\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3072\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3067\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3060\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3041\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3061\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3021\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3027\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3028\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3007\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2999\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2962\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2972\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2994\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.7136\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7119\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7109\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7090\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7075\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7065\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7048\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7031\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7016\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7003\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6985\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6973\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6959\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6942\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6929\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6916\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6903\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6889\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6875\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6860\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6842\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6832\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6815\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6801\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6788\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6772\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6760\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6746\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6730\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6715\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6700\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6690\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6673\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6655\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6641\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6628\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6611\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6596\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6580\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6564\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6548\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6527\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6512\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6495\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6477\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6458\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6439\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6420\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6404\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6381\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6363\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6341\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6320\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6301\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6279\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6259\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6235\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6214\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6191\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6165\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6148\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6123\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6098\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6069\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6042\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6017\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5995\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5972\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5942\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5912\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5890\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5857\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5829\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5796\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5764\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5735\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5713\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5682\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5657\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5623\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5596\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5558\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5528\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5495\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5458\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5427\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5396\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5361\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5337\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5298\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5264\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5221\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5200\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5162\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5136\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5102\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5067\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5036\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4987\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4961\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4944\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4886\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4861\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4823\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4799\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4756\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4742\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4693\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4666\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4626\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4606\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4563\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4535\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4512\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4482\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4439\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4406\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4392\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4355\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4334\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4314\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4248\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4253\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4207\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4184\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4159\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4116\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4113\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4066\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4055\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4038\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3971\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3952\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3934\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3906\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3867\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3858\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3836\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3819\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3801\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3770\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3753\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3734\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3720\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3717\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3668\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3655\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3623\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3600\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3602\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3558\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3553\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3561\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3531\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3487\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3475\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3457\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3474\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3423\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3403\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3400\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3368\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3387\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3358\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3334\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3333\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3302\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3294\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3291\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3272\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3252\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3250\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3206\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3209\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3225\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3180\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3196\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3177\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3167\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3161\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3143\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3117\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3125\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3109\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3106\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3081\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3077\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3066\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3071\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3056\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3011\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3029\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3018\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3008\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2999\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3005\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2998\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2958\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2980\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7136\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7124\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7108\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7095\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7078\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7066\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7050\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7033\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7019\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7006\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6995\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6976\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6964\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6949\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6935\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6920\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6905\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6891\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6878\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6860\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6846\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6836\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6822\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6807\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6793\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6780\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6763\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6749\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6737\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6720\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6704\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6692\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6680\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6661\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6648\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6634\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6615\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6602\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6585\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6562\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6551\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6534\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6513\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6500\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6477\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6462\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6446\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6426\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6407\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6388\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6369\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6349\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6326\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6308\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6283\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6262\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6241\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6220\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6197\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6167\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6149\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6128\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6097\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6078\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6050\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6024\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5974\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5950\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5918\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5892\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5858\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5833\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5808\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5771\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5748\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5724\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5692\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5660\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5633\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5598\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5570\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5531\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5508\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5467\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5441\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5402\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5370\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5336\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5309\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5277\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5238\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5208\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5177\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5134\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5108\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5071\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5045\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4972\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4941\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4905\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4882\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4832\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4814\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4766\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4755\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4721\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4691\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4644\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4616\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4588\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4541\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4516\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4477\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4462\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4437\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4417\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4347\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4352\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.4306\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4284\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4248\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4215\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4211\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4171\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4178\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4105\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4079\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4044\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4043\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4008\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3999\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3970\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3938\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3909\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3891\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3879\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3843\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3839\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3810\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3763\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3775\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3738\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3710\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3700\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3668\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3665\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3634\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3608\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3594\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3574\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3567\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3580\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3519\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3520\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3482\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3466\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3456\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3430\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3424\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3405\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3382\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3377\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3355\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3345\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3318\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3324\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3305\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3286\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3273\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3273\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3238\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3244\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3220\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3205\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3210\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3203\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3194\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3174\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3154\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3156\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3124\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3145\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3137\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3105\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3076\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3073\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3077\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3060\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3056\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3060\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3046\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3042\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3013\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3008\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3011\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2993\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2987\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2988\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7135\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7124\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7109\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7095\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7076\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7063\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7046\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7033\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7017\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7004\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6989\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6975\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6961\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6947\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6930\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6921\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6905\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6892\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6876\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6864\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6850\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6835\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6823\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6807\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6792\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6779\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6767\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6753\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6735\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6721\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6707\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6694\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6673\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6659\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6644\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6630\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6613\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6601\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6581\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6565\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6552\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6532\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6513\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6499\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6478\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6462\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6441\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6427\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6406\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6388\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6366\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6348\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6323\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6307\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6286\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6263\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6240\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6218\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6191\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6171\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6144\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6124\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6093\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6075\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6052\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6022\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5998\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5972\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5948\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5921\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5886\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5863\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5837\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5804\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5777\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5748\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5715\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5688\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5658\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5629\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5588\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5565\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5529\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5497\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5473\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5434\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5402\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5371\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5333\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5292\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5268\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5235\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5205\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5163\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5120\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5107\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5074\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5024\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5015\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4966\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4937\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4888\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4865\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4835\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4800\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4757\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4733\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4697\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4674\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4641\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4606\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4582\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4544\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4516\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4470\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4454\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4414\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4405\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4374\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4349\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4304\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4265\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4234\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4235\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4193\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4172\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4150\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4098\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4091\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4064\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4045\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4017\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3997\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3964\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3927\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3923\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3886\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3875\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3839\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3844\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3814\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3777\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3749\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3744\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3713\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3692\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3644\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3658\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3622\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3623\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3597\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3592\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3522\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3560\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3530\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3513\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3470\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3480\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3461\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3434\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3435\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3413\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3398\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3366\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3374\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3363\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3316\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3324\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3306\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3296\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3290\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3291\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3244\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3257\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3249\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3228\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3207\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3182\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3166\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3169\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3142\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3146\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3122\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3121\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3125\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3120\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3114\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3085\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3076\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3058\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3064\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3069\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3023\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3039\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3029\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3013\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3011\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2985\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2989\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2963\n"
     ]
    }
   ],
   "source": [
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Constants\n",
    "p_obfuscation = 0.1\n",
    "preprocess = \"2Step\"\n",
    "mode = \"random\"\n",
    "\n",
    "# Data Loading\n",
    "train = pd.read_csv(f\"goodbook/Random/Adding_user_item_matrix_{p_obfuscation}_top50Inditems_top100IndiUsers_Categories_{mode}.csv\", sep=\",\", names=[\"user\", \"item\"])\n",
    "test = pd.read_csv(\"goodbook/test-book0.csv\", sep=\",\", names=[\"user\", \"item\", \"rating\", \"genre\"])\n",
    "# {mode}_ : only for removal outputs\n",
    "# Sparsity Calculation\n",
    "num_unique_users = train['user'].nunique()\n",
    "num_unique_books = train['item'].nunique()\n",
    "total_possible_interactions = num_unique_users * num_unique_books\n",
    "num_interactions = train.shape[0]\n",
    "sparsity = 1.0 - (num_interactions / total_possible_interactions)\n",
    "\n",
    "print(f\"Number of unique user_ids: {num_unique_users}\")\n",
    "print(f\"Number of unique book_ids: {num_unique_books}\")\n",
    "print(f\"Sparsity of the data: {sparsity:.4f}\")\n",
    "print(f\"Length of the data: {len(train)}\")\n",
    "\n",
    "# Preparing Data\n",
    "train[\"rating\"] = 1\n",
    "train = train[[\"user\", \"item\", \"rating\"]]\n",
    "test[\"rating\"] = 1\n",
    "test = test[[\"user\", \"item\", \"rating\"]]\n",
    "\n",
    "# Algorithms\n",
    "BPR = tf.BPR(features=200, epochs=200)\n",
    "algo_ii = item_knn.ItemItem(20, feedback='implicit', use_ratings=False)\n",
    "algo_uu = user_knn.UserUser(50, feedback='implicit', use_ratings=False)\n",
    "algo_als = als.ImplicitMF(features=50)\n",
    "pop = basic.Popular()\n",
    "\n",
    "def evaluation(aname, algo, train, test, topk):\n",
    "    fittable = util.clone(algo)\n",
    "    fittable = Recommender.adapt(fittable)\n",
    "    fittable.fit(train)\n",
    "    users = test.user.unique()\n",
    "    recs = batch.recommend(fittable, users, topk)\n",
    "    recs['Algorithm'] = aname\n",
    "    return recs\n",
    "\n",
    "def run_evaluation(round, topk, train, test):\n",
    "    all_recs = []\n",
    "    all_recs.append(evaluation('ItemKNN', algo_ii, train, test, topk))\n",
    "    all_recs.append(evaluation('UserKNN', algo_uu, train, test, topk))\n",
    "    all_recs.append(evaluation('BPR', BPR, train, test, topk))\n",
    "    all_recs.append(evaluation('implicitMF', algo_als, train, test, topk))\n",
    "    all_recs.append(evaluation('pop', pop, train, test, topk))\n",
    "\n",
    "    all_recs_df = pd.concat(all_recs, ignore_index=True)\n",
    "    file_path = f\"RecSys_News/goodbook/results/Random/RS-{topk}_{p_obfuscation}_{preprocess}_{round}.csv\"\n",
    "    all_recs_df.to_csv(file_path, index=False)\n",
    "\n",
    "    rla = topn.RecListAnalysis()\n",
    "    rla.add_metric(topn.ndcg)\n",
    "    rla.add_metric(topn.hit)\n",
    "    rla.add_metric(topn.precision)\n",
    "    rla.add_metric(topn.recall)\n",
    "    rla.add_metric(topn.recip_rank)\n",
    "\n",
    "    results = rla.compute(all_recs_df, test)\n",
    "    results_file_path = f\"RecSys_News/goodbook/results/Random/results_RecSys-{topk}_{p_obfuscation}_{preprocess}_{round}.csv\"\n",
    "    results.to_csv(results_file_path, index=False)\n",
    "\n",
    "    aggres = results.groupby('Algorithm').mean()\n",
    "    aggres_file_path = f\"RecSys_News/goodbook/results/Random/aggres_RecSys-{topk}_{p_obfuscation}_{preprocess}_{round}.csv\"\n",
    "    aggres.to_csv(aggres_file_path, index=False)\n",
    "\n",
    "for round in range(1, 4):\n",
    "    for topk in [5, 10]:\n",
    "        run_evaluation(round, topk, train, test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average the recommendation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p_obfuscations = [0.01, 0.02, 0.05, 0.1]\n",
    "preprocess = \"2Step\"\n",
    "mode = \"random\"\n",
    "\n",
    "# Define the rounds and top-k values you want to average over\n",
    "rounds = [1, 2, 3]\n",
    "topks = [5, 10]\n",
    "\n",
    "# Initialize an empty list to hold DataFrames\n",
    "all_dfs = []\n",
    "\n",
    "# Read the CSV files for each p_obfuscation, round, and top-k\n",
    "for p_obfuscation in p_obfuscations:\n",
    "    for round in rounds:\n",
    "        for topk in topks:\n",
    "            file_path = f\"RecSys_News/goodbook/results/Greedy/2Step/aggres_RecSys-{topk}_{p_obfuscation}_{preprocess}_{round}.csv\"\n",
    "            df = pd.read_csv(file_path)\n",
    "            df['p_obfuscation'] = p_obfuscation\n",
    "            df['Round'] = round\n",
    "            df['TopK'] = topk\n",
    "            all_dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Group by Algorithm, TopK, and p_obfuscation to calculate mean and std for each metric\n",
    "metrics = ['ndcg', 'hit', 'precision', 'recall', 'recip_rank']\n",
    "agg_results = combined_df.groupby(['Algorithm', 'TopK', 'p_obfuscation'])[metrics].agg(['mean', 'std']).reset_index()\n",
    "agg_results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
